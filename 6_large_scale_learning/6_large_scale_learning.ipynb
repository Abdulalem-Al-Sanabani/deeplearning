{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BridgingAI Logo](../bridgingai_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Exercise 6.1: Scaling Laws\n",
    "\n",
    "---\n",
    "1. [Chinchilla Scaling Laws](#background)\n",
    "\n",
    "2. [Implementation](#implementation)\n",
    "<br/> &#9; 2.1 [Loss Function](#loss)\n",
    "<br/> &#9; 2.2 [Parameter Optimization](#optimization)\n",
    "\n",
    "3. [Analysis](#analysis)\n",
    "<br/> &#9; 3.1 [Residual Analysis](#residuals)\n",
    "<br/> &#9; 3.2 [Optimal Scaling Analysis](#scaling)\n",
    "   \n",
    "4. [References](#references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from utils import (\n",
    "    preprocess_df,\n",
    "    plot_residuals,\n",
    "    model_scaling_plot,\n",
    ")\n",
    "from tests.sanity_checks import SanityChecks\n",
    "\n",
    "# Load the Chinchilla data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df_clean = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assigmment is based on two papers: the original [Chinchilla paper](https://arxiv.org/abs/2203.15556) and [Chinchilla Scaling: A replication attempt](https://arxiv.org/abs/2404.10102). This assigment will not be as coding intensive as the previous ones, but will require you to understand the concepts of scaling laws and how they apply to deep learning models. To be specific, you will implement the *Approach 3* from the Chinchilla paper, fitting a parametric model to the data. We highly recommend reading the papers before starting the assignment. \n",
    "\n",
    "In this assignment, you will work with scaling laws in deep learning, specifically focusing on the relationships between model size, training data, and model performance. You will:\n",
    "\n",
    "1. Implement key components of scaling law analysis\n",
    "2. Analyze real training data from language models\n",
    "3. Compare your findings with the Chinchilla paper\n",
    "4. Visualize the optimal compute allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chinchilla Scaling Laws <a id=\"background\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In applied machine learning (especially in large-scale deep learning), we often want to describe how model performance changes with variations in:\n",
    "- Model size (N): Number of parameters\n",
    "- Dataset size (D): Number of training tokens/samples\n",
    "- Compute budget (C): Total training FLOPS\n",
    "\n",
    "For neural networks, so-called \"scaling laws\" have been shown to hold empirically. These equations predictably describe how model performance (loss) changes with variations in the three aforementioned quantities.\n",
    "The Chinchilla paper, for example, proposed to approximate model performance (loss) as:\n",
    "\n",
    "$$\n",
    "L(N,D) = E + \\frac{A}{N^\\alpha} + \\frac{B}{D^\\beta}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $L$: Loss\n",
    "- $N$: Model size\n",
    "- $D$: Dataset size\n",
    "- $E$: Irreducible loss\n",
    "- $A,B$: Scaling coefficients\n",
    "- $\\alpha,\\beta$: Scaling exponents\n",
    "\n",
    "Given a collection of experiments (triples of $N,D,L$), we can fit the parameters of this model to the data, and then use the model to predict the loss for new values of $N$ and $D$. This is what you will do in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementation <a id=\"implementation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Loss Function <a id=\"loss\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this section, you will have to implement the loss function that will be used to fit the model. The formula of the loss can be found in Equation (3) or Equation (11) of the [Chinchilla paper](https://arxiv.org/abs/2203.15556). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(a, b, e, alpha, beta, N, D):\n",
    "    \"\"\"\n",
    "    Calculate the log sum exp of the given parameters. This function corresponds LSE in Equation 11 of the Chinchilla paper.\n",
    "\n",
    "    Args:\n",
    "        a, b, e, alpha, beta: Scalars\n",
    "        N, D: numpy arrays of shape (num_samples,)\n",
    "\n",
    "    Returns:\n",
    "        lse: A numpy array of shape (num_samples,)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return lse\n",
    "\n",
    "\n",
    "def huber_loss(y_true, y_pred, delta=1e-3):\n",
    "    \"\"\"\n",
    "    Calculate the Huber loss between the true and predicted values.\n",
    "\n",
    "    Args:\n",
    "        y_true: A numpy array of shape (num_samples,)\n",
    "        y_pred: A numpy array of shape (num_samples,)\n",
    "        delta: A scalar for the Huber loss calculation\n",
    "\n",
    "    Returns:\n",
    "        loss: A scalar representing the Huber loss\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def huber_loss_objective(params, N, D, losses):\n",
    "    a, b, e, alpha, beta = params\n",
    "    predictions = log_sum_exp(a, b, e, alpha, beta, N, D)\n",
    "    return huber_loss(np.log(losses), predictions, delta=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following code to sanity check your implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SanityChecks.verify_implementation(log_sum_exp)\n",
    "SanityChecks.verify_implementation(huber_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optimization\"></a>\n",
    "## 2.2 Parameter Optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization objective is highly non-convex, and small deviations in the parameters can lead to large changes in the resulting predictions. We follow the approach of Hoffmann et al. (2024) and perform a grid search over the parameter using the L-BFGS-B method.\n",
    "\n",
    "**TODO**: Run the following code to fit the model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(df, verbose=True):\n",
    "    np.random.seed(42)\n",
    "    N = df[\"Model Size\"].values\n",
    "    D = df[\"Training Tokens\"].values\n",
    "    losses = df[\"loss\"].values\n",
    "\n",
    "    alpha_vals = np.arange(0, 2.5, 0.5)\n",
    "    beta_vals = np.arange(0, 2.5, 0.5)\n",
    "    e_vals = np.arange(-1, 1.5, 0.5)\n",
    "    a_vals = np.arange(0, 30, 5)\n",
    "    b_vals = np.arange(0, 30, 5)\n",
    "\n",
    "    # Perform the optimization using L-BFGS over the grid of initial values\n",
    "    best_loss = np.inf\n",
    "    best_params = None\n",
    "\n",
    "    results_dict = {}\n",
    "    search_space = [alpha_vals, beta_vals, e_vals, a_vals, b_vals]\n",
    "    total = np.prod([len(s) for s in search_space])\n",
    "    pbar = tqdm(product(*search_space), total=total)\n",
    "\n",
    "    for alpha, beta, e, a, b in pbar:\n",
    "        init_params = [a, b, e, alpha, beta]\n",
    "        result = minimize(\n",
    "            huber_loss_objective, init_params, args=(N, D, losses), method=\"L-BFGS-B\"\n",
    "        )\n",
    "        results_dict[tuple(init_params)] = {\"params\": result.x, \"loss\": result.fun}\n",
    "        if result.success and result.fun < best_loss:\n",
    "            best_loss = result.fun\n",
    "            best_params = result.x\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"New best loss: {best_loss}\")\n",
    "                print(f\"Best params: {best_params}\")\n",
    "                print(f\"Initial guess: {init_params}\")\n",
    "\n",
    "    if best_params is not None:\n",
    "        A = np.exp(best_params[0])\n",
    "        B = np.exp(best_params[1])\n",
    "        E = np.exp(best_params[2])\n",
    "        alpha = best_params[3]\n",
    "        beta = best_params[4]\n",
    "        print(f\"Best fit parameters: A={A}, B={B}, E={E}, alpha={alpha}, beta={beta}\")\n",
    "    else:\n",
    "        print(\"Optimization failed to converge.\")\n",
    "    return dict(A=A, B=B, E=E, alpha=alpha, beta=beta)\n",
    "\n",
    "\n",
    "params = fit(df, verbose=False)\n",
    "params_clean = fit(df_clean, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysis <a id=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Residual Analysis <a id=\"residuals\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll examine the residuals to assess how well our model fits the data. The residuals are the differences between the observed values and the model's predictions. A good model should have residuals that:\n",
    "\n",
    "1. Are roughly symmetric around zero\n",
    "2. Have consistent variance across the range of predictions \n",
    "\n",
    "We will visualize the residuals using scatter plots to analyze their distribution. We will start with the parameters as reported in the Chinchilla paper. Looking at the residuals, do you think these parameters are a good fit for the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_chinchilla = {\n",
    "    \"A\": 406.4,\n",
    "    \"B\": 410.7,\n",
    "    \"E\": 1.69,\n",
    "    \"alpha\": 0.34,\n",
    "    \"beta\": 0.28,\n",
    "}\n",
    "plot_residuals(\n",
    "    params_chinchilla, df, \"Residuals of original Chinchilla parameters (with outliers)\"\n",
    ")\n",
    "plot_residuals(\n",
    "    params_chinchilla,\n",
    "    df_clean,\n",
    "    \"Residuals of original Chinchilla parameters (without outliers)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the residuals of the parameters we found. Do you think these parameters are a better fit for the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(params, df, \"Scatter Plot of Residuals\")\n",
    "plot_residuals(params_clean, df_clean, \"Scatter Plot of Residuals (Cleaned)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Optimal Scaling Analysis <a id=\"scaling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section explores how model performance scales with different combinations of model size (N) and training tokens (D) under a fixed compute budget. We visualize these relationships and analyze the optimal allocation of compute resources.\n",
    "\n",
    "The key questions we examine:\n",
    "1. How does model performance change as we vary N and D while keeping compute fixed?\n",
    "2. What are the optimal values of N and D for a given compute budget?\n",
    "3. How do our findings compare to the original Chinchilla paper's conclusions?\n",
    "\n",
    "**Question:**\n",
    "Given a compute budget of C = 5.76e23 FLOPs, what would be the optimal model size (N) and number of training tokens (D) according to the scaling laws? Use the `model_scaling_plot()` visualization to help determine these values.\n",
    "\n",
    "You should give answers for the following configurations:\n",
    "1. (`params_clean`, `df_clean`)\n",
    "2. (`params_chinchilla`, `df`)\n",
    "3. (`params`, `df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (params_clean, df_clean)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (params_chinchilla, df)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (params, df)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"references\"></a>\n",
    "# 4. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556)\n",
    "- [Chinchilla Scaling: A replication attempt](https://arxiv.org/abs/2404.10102)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baidl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
